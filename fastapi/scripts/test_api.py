#!/usr/bin/env python3
"""
AgentWall API Test Script
Tests the proxy with real OpenAI API calls

Usage:
    # Local test (FastAPI running on localhost:8000)
    python test_api.py --local
    
    # Production test
    python test_api.py --prod
    
    # With your own OpenAI key (pass-through mode)
    python test_api.py --local --openai-key sk-your-key
"""

import argparse
import time
from openai import OpenAI


def test_basic_chat(client: OpenAI, test_name: str = "Basic Chat"):
    """Test basic chat completion"""
    print(f"\n{'='*50}")
    print(f"ğŸ§ª Test: {test_name}")
    print('='*50)
    
    start = time.perf_counter()
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # Cheaper for testing
            messages=[
                {"role": "user", "content": "Say 'Hello AgentWall!' in exactly 3 words."}
            ],
            max_tokens=20,
        )
        
        elapsed = (time.perf_counter() - start) * 1000
        
        print(f"âœ… Status: SUCCESS")
        print(f"â±ï¸  Latency: {elapsed:.2f}ms")
        print(f"ğŸ“ Response: {response.choices[0].message.content}")
        print(f"ğŸ”¢ Tokens: {response.usage.total_tokens}")
        
        # Check for AgentWall metadata
        if hasattr(response, 'agentwall'):
            print(f"ğŸ›¡ï¸  AgentWall Run ID: {response.agentwall.get('run_id')}")
            print(f"ğŸ›¡ï¸  AgentWall Step: {response.agentwall.get('step')}")
            print(f"ğŸ›¡ï¸  AgentWall Cost: ${response.agentwall.get('cost_usd', 0):.6f}")
        
        return True
        
    except Exception as e:
        elapsed = (time.perf_counter() - start) * 1000
        print(f"âŒ Status: FAILED")
        print(f"â±ï¸  Latency: {elapsed:.2f}ms")
        print(f"ğŸš¨ Error: {e}")
        return False


def test_streaming(client: OpenAI, test_name: str = "Streaming"):
    """Test streaming chat completion"""
    print(f"\n{'='*50}")
    print(f"ğŸ§ª Test: {test_name}")
    print('='*50)
    
    start = time.perf_counter()
    
    try:
        stream = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "Count from 1 to 5."}
            ],
            max_tokens=50,
            stream=True,
        )
        
        print("ğŸ“¡ Streaming response: ", end="", flush=True)
        chunks = 0
        content = ""
        
        for chunk in stream:
            chunks += 1
            if chunk.choices[0].delta.content:
                content += chunk.choices[0].delta.content
                print(chunk.choices[0].delta.content, end="", flush=True)
        
        elapsed = (time.perf_counter() - start) * 1000
        
        print()  # New line
        print(f"âœ… Status: SUCCESS")
        print(f"â±ï¸  Latency: {elapsed:.2f}ms")
        print(f"ğŸ“¦ Chunks: {chunks}")
        
        return True
        
    except Exception as e:
        elapsed = (time.perf_counter() - start) * 1000
        print(f"âŒ Status: FAILED")
        print(f"â±ï¸  Latency: {elapsed:.2f}ms")
        print(f"ğŸš¨ Error: {e}")
        return False


def test_dlp_detection(client: OpenAI, test_name: str = "DLP Detection"):
    """Test DLP - should mask sensitive data"""
    print(f"\n{'='*50}")
    print(f"ğŸ§ª Test: {test_name}")
    print('='*50)
    
    start = time.perf_counter()
    
    try:
        # This contains a fake API key - should be masked
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "My API key is sk-1234567890abcdefghijklmnop. What is 2+2?"}
            ],
            max_tokens=20,
        )
        
        elapsed = (time.perf_counter() - start) * 1000
        
        print(f"âœ… Status: SUCCESS (DLP should have masked the key)")
        print(f"â±ï¸  Latency: {elapsed:.2f}ms")
        print(f"ğŸ“ Response: {response.choices[0].message.content}")
        
        return True
        
    except Exception as e:
        elapsed = (time.perf_counter() - start) * 1000
        # DLP might block the request entirely
        if "blocked" in str(e).lower() or "dlp" in str(e).lower():
            print(f"âœ… Status: SUCCESS (DLP blocked the request)")
        else:
            print(f"âŒ Status: FAILED")
        print(f"â±ï¸  Latency: {elapsed:.2f}ms")
        print(f"ğŸš¨ Error: {e}")
        return "blocked" in str(e).lower()


def test_run_tracking(client: OpenAI, test_name: str = "Run Tracking"):
    """Test run-level tracking with multiple requests"""
    print(f"\n{'='*50}")
    print(f"ğŸ§ª Test: {test_name}")
    print('='*50)
    
    run_id = f"test-run-{int(time.time())}"
    
    try:
        # Make 3 requests with same run_id
        for i in range(3):
            start = time.perf_counter()
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": f"Step {i+1}: What is {i+1}+{i+1}?"}
                ],
                max_tokens=20,
                extra_headers={
                    "X-AgentWall-Run-ID": run_id,
                }
            )
            
            elapsed = (time.perf_counter() - start) * 1000
            print(f"  Step {i+1}: {response.choices[0].message.content[:30]}... ({elapsed:.0f}ms)")
        
        print(f"âœ… Status: SUCCESS")
        print(f"ğŸ†” Run ID: {run_id}")
        print(f"ğŸ“Š Steps: 3")
        
        return True
        
    except Exception as e:
        print(f"âŒ Status: FAILED")
        print(f"ğŸš¨ Error: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="Test AgentWall API")
    parser.add_argument("--local", action="store_true", help="Test local server (localhost:8000)")
    parser.add_argument("--prod", action="store_true", help="Test production (api.agentwall.io)")
    parser.add_argument("--openai-key", type=str, help="OpenAI API key for pass-through mode")
    parser.add_argument("--agentwall-key", type=str, default="aw-test-key", help="AgentWall API key")
    args = parser.parse_args()
    
    # Determine base URL
    if args.local:
        base_url = "http://localhost:8000/v1"
        env = "LOCAL"
    elif args.prod:
        base_url = "https://api.agentwall.io/v1"
        env = "PRODUCTION"
    else:
        print("âŒ Please specify --local or --prod")
        return
    
    # Determine API key
    api_key = args.openai_key if args.openai_key else args.agentwall_key
    
    print("\n" + "="*60)
    print("ğŸ›¡ï¸  AgentWall API Test Suite")
    print("="*60)
    print(f"ğŸŒ Environment: {env}")
    print(f"ğŸ”— Base URL: {base_url}")
    print(f"ğŸ”‘ API Key: {api_key[:10]}...")
    
    # Create client
    client = OpenAI(
        api_key=api_key,
        base_url=base_url,
    )
    
    # Run tests
    results = []
    
    results.append(("Basic Chat", test_basic_chat(client)))
    results.append(("Streaming", test_streaming(client)))
    results.append(("DLP Detection", test_dlp_detection(client)))
    results.append(("Run Tracking", test_run_tracking(client)))
    
    # Summary
    print("\n" + "="*60)
    print("ğŸ“Š Test Summary")
    print("="*60)
    
    passed = sum(1 for _, r in results if r)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {status} - {name}")
    
    print(f"\nğŸ¯ Result: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All tests passed!")
    else:
        print("âš ï¸  Some tests failed")


if __name__ == "__main__":
    main()
